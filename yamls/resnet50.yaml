run_name: asgn9-run1                   # Name of the training run used for checkpointing and other logging
is_train: true                               # Trains the model if true, otherwise runs evaluation
seed: 17                                     # Random seed
max_duration: 90ep                           # Duration to train specified as a Time string
device_train_microbatch_size: auto           # Size of microbatch, 'auto' means Composer will choose the optimal value

# Model
model:
  name: resnet50           # Name of the ResNet model to train either resnet{18, 34, 50, 101, 152}
  loss_name: cross_entropy # Name of the loss function either 'cross_entropy' or 'binary_cross_entropy'
  num_classes: 1000        # Number of classes in the classification task

# Training Dataset Parameters
train_dataset:
  is_streaming: false                    # Whether or not your data is in a remote location (e.g. a S3 bucket)
  path: /datasets/Imagenet      # Path to S3 bucket if streaming, otherwise path to local data directory
  local: /tmp/mds-cache/mds-imagenet1k/ # Local cache when streaming data
  resize_size: -1                       # Training image resize size before crop, -1 means no resize
  crop_size: 224                        # Training image crop size
  batch_size: 1024                      # Training dataloader batch size per device

# Validation Dataset Parameters
eval_dataset:
  is_streaming: false                    # Whether or not your data is in a remote location (e.g. a S3 bucket)
  path: /datasets/Imagenet      # S3 bucket if streaming, otherwise path to local data
  local: /tmp/mds-cache/mds-imagenet1k/ # Local cache when streaming data
  resize_size: 256                      # Evaluation image resize size before crop
  crop_size: 224                        # Evaluation image crop size
  batch_size: 1024                      # Evaluation dataloader batch size per device

# Optimizer Parameters
optimizer:
  lr: 2.048
  momentum: 0.875
  weight_decay: 5.0e-4

# LR Scheduler Parameters
scheduler:
  t_warmup: 8ep # Duration of learning rate warmup specified as a Time string
  alpha_f: 0.0  # Base learning rate multiplier to decay to

# WORKING one
loggers:
  progress_bar:
    progress_bar_refresh_rate: 1
    log_interval: 1ba
    batch_level_metrics: true


# null for baseline or for recipe, either ["mild", "medium", "hot"] in order of increasing training time and accuracy
recipe_name: "mild"

# Updated parameters for mild recipe
mild:
  model.loss_name: binary_cross_entropy
  train_dataset.crop_size: 176
  eval_dataset.resize_size: 232
  max_duration: 36ep

# Updated parameters for medium recipe
medium:
  model.loss_name: binary_cross_entropy
  train_dataset.crop_size: 176
  eval_dataset.resize_size: 232
  max_duration: 135ep

# Updated parameters for hot recipe
hot:
  model.loss_name: binary_cross_entropy
  train_dataset.crop_size: 176
  eval_dataset.resize_size: 232
  max_duration: 270ep

# Save checkpoint parameters
save_folder: './{run_name}/ckpt'                   # e.g. './{run_name}/ckpt' (local) or 's3://mybucket/mydir/{run_name}/ckpt' (remote)
save_interval: 1ep             # Interval to checkpoint based on time string
save_num_checkpoints_to_keep: 2 # Cleans up checkpoints saved locally only!

# Load checkpoint parameters
load_path: './asgn9-run1/ckpt/latest-rank0.pt'     # e.g. './ckpt/latest-rank{rank}.pt' (local) or 's3://mybucket/mydir/ckpt/latest-rank{rank}.pt' (remote)
